{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3Ly2fuLAjKllZryAdCsPk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/semaHbo/job-clustering-salary-prediction/blob/main/predict_jobs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kDGtEYwHpTnG"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "!tar -xzf spark-3.3.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "import findspark\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\"\n",
        "\n",
        "findspark.init()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"JobSalaryPrediction\").getOrCreate()"
      ],
      "metadata": {
        "id": "zU4nefcXpoYF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08OLLIJWpvYn",
        "outputId": "784a0434-5793-4013-e131-60fda7c28f97"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/job-clustering-salary-prediction/data/raw\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrytsQ7T1hAr",
        "outputId": "38772564-55b4-4ce9-ea50-55b2c9ecbaa8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jobs_sample.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df = df.withColumn(\"Yil\", col(\"Yil\").cast(\"int\"))\n",
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYWdoDfuVXzb",
        "outputId": "65251bc9-8197-49f3-b0fa-948cc085d429"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- Deneyim_Seviyesi: string (nullable = true)\n",
            " |-- Calisma_Tipi: string (nullable = true)\n",
            " |-- Sirket_Buyuklugu: string (nullable = true)\n",
            " |-- Sirket_Ulke: string (nullable = true)\n",
            " |-- Remote_Tipi: string (nullable = true)\n",
            " |-- Kita: string (nullable = true)\n",
            " |-- Yil: integer (nullable = true)\n",
            " |-- pozisyon_token: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- pozisyon_vec: vector (nullable = true)\n",
            " |-- Deneyim_Seviyesi_Encoded: double (nullable = false)\n",
            " |-- Calisma_Tipi_Encoded: double (nullable = false)\n",
            " |-- Sirket_Buyuklugu_Encoded: double (nullable = false)\n",
            " |-- Sirket_Ulke_Encoded: double (nullable = false)\n",
            " |-- Remote_Tipi_Encoded: double (nullable = false)\n",
            " |-- Kita_Encoded: double (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, Word2Vec, StringIndexer, VectorAssembler\n",
        "from pyspark.ml.regression import GBTRegressionModel\n",
        "from pyspark.sql.functions import lower, regexp_replace\n",
        "import pandas as pd\n",
        "\n",
        "# Spark başlat\n",
        "spark = SparkSession.builder.appName(\"PredictSalaries\").getOrCreate()\n",
        "\n",
        "# CSV dosyasının yolu\n",
        "csv_path = \"/content/drive/MyDrive/job-clustering-salary-prediction/data/raw/jobs_sample.csv\"\n",
        "\n",
        "#  Veriyi oku\n",
        "df = spark.read.option(\"header\", True).csv(csv_path)\n",
        "\n",
        "#  Temizlik: açıklamaları normalize et\n",
        "df = df.withColumn(\"description\", lower(regexp_replace(\"description\", \"<[^>]+>\", \" \")))\n",
        "\n",
        "#  Pozisyon sütununu tokenize et\n",
        "tokenizer = Tokenizer(inputCol=\"description\", outputCol=\"pozisyon_token\")\n",
        "df = tokenizer.transform(df)\n",
        "\n",
        "# 4. Word2Vec modelini yükle veya yeniden fit et\n",
        "w2v = Word2Vec(inputCol=\"pozisyon_token\", outputCol=\"pozisyon_vec\", vectorSize=10, minCount=1, seed=42)\n",
        "w2v_model = w2v.fit(df)\n",
        "df = w2v_model.transform(df)\n",
        "\n",
        "# Kategorik sütunlar\n",
        "kategorik_sutunlar = [\n",
        "    \"Deneyim_Seviyesi\", \"Calisma_Tipi\", \"Sirket_Buyuklugu\",\n",
        "    \"Sirket_Ulke\", \"Remote_Tipi\", \"Kita\"\n",
        "]\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "df = df.withColumn(\"Yil\", col(\"Yil\").cast(\"int\"))\n",
        "\n",
        "\n",
        "# StringIndexer uygula\n",
        "for col in kategorik_sutunlar:\n",
        "    indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_Encoded\", handleInvalid=\"keep\")\n",
        "    df = indexer.fit(df).transform(df)\n",
        "\n",
        "#  VectorAssembler ile tüm özellikleri birleştir\n",
        "ozellikler = [\n",
        "    \"pozisyon_vec\",\n",
        "    \"Deneyim_Seviyesi_Encoded\",\n",
        "    \"Calisma_Tipi_Encoded\",\n",
        "    \"Sirket_Buyuklugu_Encoded\",\n",
        "    \"Sirket_Ulke_Encoded\",\n",
        "    \"Remote_Tipi_Encoded\",\n",
        "    \"Kita_Encoded\",\n",
        "    \"Yil\"\n",
        "]\n",
        "\n",
        "assembler = VectorAssembler(inputCols=ozellikler, outputCol=\"features_enriched\")\n",
        "df = assembler.transform(df)\n",
        "\n",
        "#  Eğitimli GBT modelini yükle(model_training_2 icindeki model)\n",
        "model_path = \"/content/drive/MyDrive/job-clustering-salary-prediction/models/gbt_salary_model\"\n",
        "model = GBTRegressionModel.load(model_path)\n",
        "\n",
        "#  Tahmin\n",
        "predictions = model.transform(df)\n",
        "\n",
        "# Sonuçları pandas ile kaydet\n",
        "results = predictions.select(\"id\", \"title\", \"prediction\").toPandas()\n",
        "\n",
        "import numpy as np\n",
        "results[\"gercek_maas_usd\"] = np.exp(results[\"prediction\"])\n",
        "\n",
        "output_path = \"/content/drive/MyDrive/job-clustering-salary-prediction/data/output/predicted_salaries.csv\"\n",
        "results.to_csv(output_path, index=False)\n",
        "\n",
        "print(\" Tahmin tamamlandı. Sonuç kaydedildi:\")\n",
        "print(output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIouYdDBN5sy",
        "outputId": "6319c529-24fd-4f4d-c974-6aed5684a254"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tahmin tamamlandı. Sonuç kaydedildi:\n",
            "/content/drive/MyDrive/job-clustering-salary-prediction/data/output/predicted_salaries.csv\n"
          ]
        }
      ]
    }
  ]
}